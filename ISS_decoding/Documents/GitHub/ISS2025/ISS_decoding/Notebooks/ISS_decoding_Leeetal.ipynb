{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISS_decoding of preprocessed files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook guides you through the steps necessary for the decoding of ISS image data that have been preprocessed using our `ISS_preprocessing` module.\n",
    "\n",
    "In this step, we make use of the starfish library to extract the information contained in our images. starfish is a Python library for processing images of image-based spatial transcriptomics. You can read more about it here: https://spacetx-starfish.readthedocs.io/en/latest/\n",
    "\n",
    "In the following steps, we first format our images to a starfish-compatible format (SpaceTx), and provide some information about our experiment design. \n",
    "Once this is completed, we can proceed to the actual decoding of the data from the SpaceTx images.\n",
    "Format images.\n",
    "\n",
    "\n",
    "For this notebook to work correctly, you should have a specific folder for each one of the sections you want to process, and each folder should contain the following subfolders tree: `/preprocessing/ReslicedTiles`. Under `/preprocessing` you might still have other subfolders such as `/mipped/`, `/OME_tiffs/` and `/stitched/`, but these are irrelevant at this stage, and will not exist in the output folder from `ISS_CARE`, if that's the choice you've made for denoising the images. \n",
    "\n",
    "The important thing is that you have a `/preprocessing/ReslicedTiles/`, because the resliced images are the starting point of the preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We start by importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ISS_decoding.SpaceTx_format as STX\n",
    "import ISS_decoding.decoding as DEC\n",
    "import ISS_decoding.qc_metrics as QC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the path where your preprocessed sections are saved\n",
    "\n",
    "Here we input the path to each one of the samples as an element of a list. Each element needs to contain the full path to the sample folder. We consider as \"sample folder\" the parent folder to `/preprocessing/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=['/home/marco/Downloads/media/marco/mountstuff/rfl_test/']\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the images to SpaceTx format\n",
    "\n",
    "The first thing to do before we can start the actual decoding is to transform our images (the resliced tiles) to the SpaceTx format.\n",
    "\n",
    "To read more about the SpaceTx format, read the following: https://github.com/spacetx/sptx-format\n",
    "\n",
    "In order to complete this step, you need to input the path to a `codebook_csv`. This is a file that associates a unique color sequence across ISS cycles to each gene. This file is a comma separated file with no header, in which the first column contains the gene name, while  columns 2 to 6 (in case of a 6 cycle experiment) contain numbers representing the expected positive DO_decorator in each cycle for that gene. \n",
    "\n",
    "Let's look at the variables are taken by the function:\n",
    "\n",
    "`filenames` = type: `list`. This list contains the names of the subfolders in the ReslicedTiles folder. Depending on how many cycles you have in your experiment, you will have to shorten it. For example, if you only have 4 cycles, you should remove: 'Base_5_stitched','Base_6_stitched'. \n",
    "\n",
    "`tile_dim` = type: `int`. The dimensions of your ReslicedTiles. Default = 2000. Make sure this matches the `tile_dim` size you used in the `tile_stitched_images` function in the `ISS_preprocessing` module.\n",
    "\n",
    "`pixelscale`  = type: `int`. This is the size of the pixels in microns. This is needed if you want the coordinates of the spot to be output in microns, and will depend on your microscope settings. Set to 1 if you want the data to be on a coordinate scale. Default = 0.1625.\n",
    "\n",
    "`channels` = type: `list`. The channels, in the order they were acquired in the microscope. Default = [\"AF750\", \"Cy5\", \"Cy3\", \"AF488\", \"DAPI\"]\n",
    "\n",
    "`DO_decorators` =  type: `list` **This point can be tricky to understant.** This shows how you associate the numbers in the codebook (ie 1,2,3,4) to a specific list of colors (DO_decorator) . In our lab, 1,2,3,4 correspond to  [\"AF750\", \"488\", \"Cy3\",  \"Cy5\"]. Default =  [\"AF750\", \"488\", \"cy3\",  \"Cy5\"]. Users who will follow our barcode design and readout schemes should not change this.\n",
    "\n",
    "`folder_spacetx`  = this is the name of the folder containing where the SpaceTx files will be saved. Default = SpaceTX_format. \n",
    "\n",
    "`nuclei_channel`  = type: `int`. This is the number of the channel that corresponds to your nuclei stained image. This is 1-indexed and our default = 5. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sample in samples:\n",
    "    STX.make_spacetx_format(path = sample,\n",
    "    codebook_csv = '/home/marco/Documents/GitHub/ISS2025/codebook_allposibilities_5colors.csv',\n",
    "    filenames=['Base_1_stitched', 'Base_2_stitched', \n",
    "               'Base_3_stitched', 'Base_4_stitched', 'Base_5_stitched'],\n",
    "    tile_dim=4000,\n",
    "    pixelscale=1,\n",
    "    channels=[\"AF750\", \"Cy5\", \"Cy3\", \"AF488\", \"DAPI\", \"At425\"],\n",
    "    DO_decorators=[\"AF750\", \"AF488\", \"Cy3\", \"Cy5\", \"At425\"],\n",
    "    folder_spacetx='SpaceTX_format_rfl',\n",
    "    nuclei_channel=5,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode the SpaceTx formatted data\n",
    "\n",
    "\n",
    "At this stage, after running the above code block, you should have successfully transformed your preprocessed resliced tiles into the SpaceTx format. Each `/preprocessing/SpaceTX_format/` should now contain a file called `experiment.json`\n",
    "\n",
    "To decode the images, we now need to use the `process_experiment` function.\n",
    "\n",
    "\n",
    "In brief, the function will take each individual SpaceTx image file, looks for the same spot across cycles, deduce a colour sequence for each spot across the different cycles, and match the extracted sequence to the `codebook` we provided previously. \n",
    "\n",
    "In detail, this process is actually a bit more complex and several steps happen within the `process_experiment` function. We suggest you to have a look at the relevant part of the manual for exhaustive explanation of what happens under the hood. \n",
    "\n",
    "### Changing decoding parameters\n",
    "\n",
    "Modifying some of  the input parameters of the `process_experiment` function, it is possible to explore a range of settings to optimize the decoding for every specific experiment, if necessary.\n",
    "\n",
    "`Exp_path`: here you have to specify the path to the `experiment.json` described above. This is normally inside the `SpaceTX_format` subfolder.\n",
    "\n",
    "`Output`: This is the output folder, where the decoded data will be deposited. We recommend that this path points to a new empty folder, since the function generates and individual csv for every tile processed.\n",
    "\n",
    "`Register`: select `True` if you want to register/align your images and `False` if you don’t want to align your images. In principle, this should be already taken care of by the `ISS_preprocessing` module. Nevertheles, this step is also recommended, as sometimes small adjustments in the registration of images improve this step.\n",
    "\n",
    "`Register_dapi`: specify `True` if you want to align your images based on Dapi/ nuclear staining. If it’s specified as `False`, the alignment will be done based on a pseudoanchor(please read the glossary on the manual to know what this is). This parameter only is considered if the parameter `Register==True`.\n",
    "\n",
    "`Masking radius`: the radius of the top hat filter for spot detection. Depending on the size, it will “smoothen” your data to a different extent. The standard values go between 7 and 15. We recommend 7. Refer to the manual for further explanations.\n",
    "\n",
    "`Threshold`: Defines the minimum intensity that a spot should have in order to be detected. Decreasing the threshold increases the number of detected spots, but also increases the chance of background signal being counted as a spot. \n",
    "\n",
    "`Sigma vals`:  correspond to min_sigma, max_sigma, num_sigma. See https://spacetx-starfish.readthedocs.io/en/latest/api/spots/index.html#spot-finding. Our default values are set in a way that allow us to capture signals in our experimental settings, on both Leica and Zeiss and at both 20x and 40x magnifications.\n",
    "\n",
    "`Decode_mode`: two options are given: ‘PRMC’: per round max channel OR ‘MD’, metric distance. We suggest to use PRMC. More information on how the two methods differ are in the manual.\n",
    "\n",
    "`Normalization method`: ‘MH’ or ‘CPTZ’. These are two alternative image normalization methods. We normally advise to use 'MH' for ISS data. Please refer to the manual to understand the differences.\n",
    "\n",
    "However the above parameters are specified, the output decoded files will always be .csv files consisting essentially of the location (XY position) and identity (gene) of every spot decoded. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading processed FOVs: Can only use .str accessor with string values!\n",
      "decoding fov_000\n",
      "getting images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 38.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not registering images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 25/25 [00:00<00:00, 929.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing channel intensities\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mDEC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/SpaceTX_format_rfl/experiment.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/decoded_dense/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregister\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregister_dapi\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmasking_radius\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.002\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msigma_vals\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# min, max and number\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPRMC\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalization_method\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMH\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdense\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/site-packages/ISS_decoding/decoding.py:344\u001b[39m, in \u001b[36mprocess_experiment\u001b[39m\u001b[34m(exp_path, output, register, register_dapi, masking_radius, threshold, sigma_vals, decode_mode, normalization_method, dense)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    342\u001b[39m     decode_mode_to_use = decode_mode\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m decoded = \u001b[43mISS_pipeline_dense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodebook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregister\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregister\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregister_dapi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregister_dapi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmasking_radius\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmasking_radius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43msigma_vals\u001b[49m\u001b[43m=\u001b[49m\u001b[43msigma_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_mode_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchannel_normalization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalization_method\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[38;5;66;03m# decoded is a list of dataframes; no QC scoring needed\u001b[39;00m\n\u001b[32m    357\u001b[39m df = pd.concat(decoded, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/site-packages/ISS_decoding/decoding.py:90\u001b[39m, in \u001b[36mISS_pipeline_dense\u001b[39m\u001b[34m(fov, codebook, register, register_dapi, masking_radius, threshold, sigma_vals, decode_mode, channel_normalization)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[32m     88\u001b[39m     sbp = starfish.image.Filter.ClipPercentileToZero(p_min=\u001b[32m80\u001b[39m, p_max=\u001b[32m99.999\u001b[39m, level_method=Levels.SCALE_BY_CHUNK)\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m scaled = \u001b[43msbp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_processes\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_place\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m bd = FindSpots.BlobDetector(\n\u001b[32m     93\u001b[39m     min_sigma=sigma_vals[\u001b[32m0\u001b[39m],\n\u001b[32m     94\u001b[39m     max_sigma=sigma_vals[\u001b[32m1\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     97\u001b[39m     measurement_type=\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     98\u001b[39m )\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Instead of hardcoding channels, determine available channels dynamically.\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# Assuming primary_image is an xarray DataArray, we can get channel indices like this:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/site-packages/starfish/core/pipeline/algorithmbase.py:23\u001b[39m, in \u001b[36mAlgorithmBase.run_with_logging.<locals>.helper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhelper\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     25\u001b[39m         method_class_str = \u001b[38;5;28mstr\u001b[39m(args[\u001b[32m0\u001b[39m].\u001b[34m__class__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/site-packages/starfish/core/image/Filter/match_histograms.py:112\u001b[39m, in \u001b[36mMatchHistograms.run\u001b[39m\u001b[34m(self, stack, in_place, verbose, n_processes, *args)\u001b[39m\n\u001b[32m    110\u001b[39m reference_image = \u001b[38;5;28mself\u001b[39m._compute_reference_distribution(stack)\n\u001b[32m    111\u001b[39m apply_function = partial(\u001b[38;5;28mself\u001b[39m._match_histograms, reference=reference_image)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m result = \u001b[43mstack\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapply_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_place\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_place\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_processes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_processes\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/site-packages/starfish/core/imagestack/imagestack.py:840\u001b[39m, in \u001b[36mImageStack.apply\u001b[39m\u001b[34m(self, func, group_by, in_place, verbose, n_processes, level_method, *args, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m in_place:\n\u001b[32m    838\u001b[39m     \u001b[38;5;66;03m# create a copy of the ImageStack, call apply on that stack with in_place=True\u001b[39;00m\n\u001b[32m    839\u001b[39m     image_stack = deepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m     \u001b[43mimage_stack\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_place\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_processes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m image_stack\n\u001b[32m    849\u001b[39m \u001b[38;5;66;03m# Add a wrapper to the function to be applied.  This wrapper will grab control after the\u001b[39;00m\n\u001b[32m    850\u001b[39m \u001b[38;5;66;03m# function has been applied and perform per-chunk transformations like clip and\u001b[39;00m\n\u001b[32m    851\u001b[39m \u001b[38;5;66;03m# scale-by-chunk.  Scaling across an entire ImageStack is performed after all the chunks are\u001b[39;00m\n\u001b[32m    852\u001b[39m \u001b[38;5;66;03m# returned.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/site-packages/starfish/core/imagestack/imagestack.py:856\u001b[39m, in \u001b[36mImageStack.apply\u001b[39m\u001b[34m(self, func, group_by, in_place, verbose, n_processes, level_method, *args, **kwargs)\u001b[39m\n\u001b[32m    853\u001b[39m bound_func = partial(ImageStack._in_place_apply, func, level_method=level_method)\n\u001b[32m    855\u001b[39m \u001b[38;5;66;03m# execute the processing workflow\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbound_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_processes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[38;5;66;03m# scale based on values of whole image\u001b[39;00m\n\u001b[32m    865\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level_method == Levels.SCALE_BY_IMAGE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/site-packages/starfish/core/imagestack/imagestack.py:949\u001b[39m, in \u001b[36mImageStack.transform\u001b[39m\u001b[34m(self, func, group_by, verbose, n_processes, *args, **kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m results = tpe.map(mp_applyfunc, selectors)\n\u001b[32m    947\u001b[39m \u001b[38;5;66;03m# Note: results is [None, ...] if executing an in-place workflow\u001b[39;00m\n\u001b[32m    948\u001b[39m \u001b[38;5;66;03m# Note: this return must be inside the context manager or the Pool will deadlock\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselectors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for sample in samples:\n",
    "    DEC.process_experiment(exp_path = sample+'/SpaceTX_format_rfl/experiment.json', \n",
    "    output = sample+'/decoded_dense/',  \n",
    "    register = False,\n",
    "    register_dapi = False,\n",
    "    masking_radius = 7, \n",
    "    threshold = 0.002, \n",
    "    sigma_vals = [1, 10, 30], # min, max and number\n",
    "    decode_mode = 'PRMC',\n",
    "    normalization_method = 'MH',\n",
    "    dense=True\n",
    "            )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the decoded data.\n",
    "\n",
    "As mentioned in the previous text, every single SpaceTX file (corresponding to a ReslicedTile) is decoded independently. This makes the decoding feasible, though slow, even on old laptops.\n",
    "\n",
    "The last step is then to concatenate all the decoded csv files that belong to a single experiment . For this, we use the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marco/Downloads/media/marco/mountstuff/rfl_test/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/marco/Downloads/media/marco/mountstuff/rfl_test//decoded_dense/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m (sample)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mDEC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate_starfish_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/decoded_dense/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                            \u001b[49m\u001b[43moutpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/decoded_dense/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ISS_decoding/lib/python3.11/site-packages/ISS_decoding/decoding.py:376\u001b[39m, in \u001b[36mconcatenate_starfish_output\u001b[39m\u001b[34m(path, outpath, tag)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m csv_files = \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    377\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(csv_files))\n\u001b[32m    378\u001b[39m append_data = []\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/marco/Downloads/media/marco/mountstuff/rfl_test//decoded_dense/'"
     ]
    }
   ],
   "source": [
    "for sample in samples:\n",
    "    print (sample)\n",
    "    DEC.concatenate_starfish_output(path=sample+'/decoded_dense/',\n",
    "                            outpath=sample+'/decoded_dense/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "\n",
    "\n",
    "\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the decoded data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After combining the csv files for every individual tile, we should get as an output a big table (saved in csv) containing the information of our raw decoded spots. The main columns are: \n",
    "\n",
    "1. The location of the decoded spot (columns “xc” and “yc”) and \n",
    "\n",
    "2. the identity of every spot (column: “target”). \n",
    "\n",
    "Similarly to what happens in NGS experiments, there \"raw\" reads migh have variable quality and one key step before performing downstream analyses is to assess this quality and filter the data if necessary (**spoiler alert: it is always necessary to do some level of filtering**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, we'll need to work on each sample individually. It is important to assess the quality of the reads on individual sample, for obvious reasons.\n",
    "\n",
    "First of all we read the combined CSV file for one sections. You will have to input the path down here accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads=pd.read_csv('/path/to/your/decoding_output/decoded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of extracted raw reads for this section is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding read quality\n",
    "\n",
    "To have an idea of how the read quality looks like, we can generate a violin plot of the qualities per cycle using the `quality_per_cycle` function. The function gets the data from the `reads` table above. The number of cycles needs to be specified manually by the user. \n",
    "\n",
    "You can have a look at the manual to understand how the quality is calculated. Summing up, 1 is the theoretical maximum and 0.25 the theoretical minimum in a 4 colour setting. The more your violin plots are shifted towards 1, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QC.quality_per_cycle(reads,cycles=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful plot to generate is to see how quality score metrics reflect whether a read has a match on the codebook (\"assigned\") or not (\"non assigned\"). We plot the `quality_minimum` and `quality_mean` against the assignment/non assignment to understand which is the best strategy to filter our data. Ideally we should infer from this plot a good quality threshold for filtering our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QC.compare_scores(reads,score1='quality_mean',score2='quality_minimum',hue='assigned',kind='hist',color='#3266a8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command does the same, but only on a single score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QC.plot_scores(reads,on='quality_mean',hue='assigned',log_scale=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the data\n",
    "\n",
    "There are different strategies to filter the data, depending on what the above plots show. You can refer to the manual for more specific example.\n",
    "\n",
    "A general common sense criterion is to filter out all the reads whose `quality_minimum` is < 0.5\n",
    "This discards all the reads that show poor quality in **at least one cycle**. This is quite a conservative criterion, but as a rule of thumb is a good one.\n",
    "\n",
    "\n",
    "Other methods for filtering are also described in the relevant part of the manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_filt=QC.filter_reads(reads,min_quality_minimum=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of filtered reads for this section is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reads_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot expression data\n",
    "\n",
    "After quality-filtering, a sensible thing to do is to plot the gene expression decoded from your tissue. \n",
    "\n",
    "Parameters `xcolumn` and `y column` define the XY positions of your spots in the `reads_filt` dataframe. \n",
    "\n",
    "`key` points to the column containing the gene identity of your spots in the `reads_filt` dataframe.\n",
    "\n",
    "`genes` allows to plot a single gene per plot (=`individual`), or to plots all genes in a single plot (=`all`)\n",
    "\n",
    "`size`= sets the dot size\n",
    "\n",
    "`background`= sets the background color\t\n",
    "\n",
    "`title_color`= sets the color of the title for each plot.\n",
    "\n",
    "`colorcode`= sets the color of the expression dots\n",
    "\n",
    "`figuresize`=(10,10) sets the size of the plot\n",
    "\n",
    "`save`= defaults to `None`. If `True` saves the plot in the speficied `format`\n",
    "\n",
    "`format`= saves the plot to a specific format (ie `pdf`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QC.plot_expression(reads,key='target',colorcode=['red'],xcolumn='xc',ycolumn='yc',genes='individual',size=8,background='black',title_color='white',figuresize=(10,10),save=None,format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful functions\n",
    "\n",
    "`quality_per_gene`: this function plots the quality of the reads assigned to each gene. Since every gene has an associated sequence of colors across cycles, we might have a big quality bias between different genes arising just because of the colour sequence (ie. if a channel has always a bad signal/noise, genes with many cycles in that channels will always have lower quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QC.quality_per_gene(reads,on='quality_mean',gene_name='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_frequencies`: allows us to plot the relative abundance of the decoded dots for each gene. This is useful to identify potential decoding artefacts. For example, a gene that looks 1000 times more abundant than the second more represented gene, should raise an eyebrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QC.plot_frequencies(reads,on='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISS_decoding",
   "language": "python",
   "name": "iss_decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
